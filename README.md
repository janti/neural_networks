"# Tree Classification with Deep Learning

A comprehensive machine learning project implementing transfer learning with ResNet architectures for automated tree species identification from urban street images.

## ğŸŒ³ Project Overview

This project demonstrates the application of convolutional neural networks (CNNs) for multi-class image classification, specifically focusing on identifying 23 different tree species from photographs. Using PyTorch and transfer learning techniques, multiple ResNet architectures were trained and evaluated to achieve optimal performance.

### Key Achievements
- **89.19% accuracy** with ResNet50 fine-tuning approach
- **6 different model configurations** tested and compared
- **Comprehensive evaluation** including n-best classification analysis
- **Robust data preprocessing** with effective augmentation strategies

## ğŸ“Š Dataset

**Tree Dataset of Urban Street Classification** (Kaggle)
- **23 tree species** including:
  - Acer palmatum, Ginkgo biloba, Magnolia grandiflora
  - Cedrus deodara, Flowering cherry, Platanus
  - And 17 additional species
- **4,804 total images** distributed across:
  - Training: 3,850 images
  - Validation: 482 images
  - Test: 472 images

## ğŸ—ï¸ Model Architectures

### Tested Configurations

1. **ResNet18** (Fine-tuning) - 84.96% accuracy
2. **ResNet50** (Fine-tuning) - **89.62% accuracy** â­
3. **ResNet18** (Feature extraction) - 56.14% accuracy
4. **ResNet50** (Feature extraction) - 54.45% accuracy
5. **ResNet18** (High learning rate) - Various configurations
6. **ResNet50** (Extended training) - Long-term optimization

### Best Performing Model
- **Architecture**: ResNet50 with fine-tuning
- **Test Accuracy**: 89.62%
- **Precision**: 91.08%
- **Recall**: 89.62%
- **F1-Score**: 89.70%

## ğŸ“ˆ Performance Metrics

### N-Best Classification Results (ResNet50)
- **Top-1**: 89.62%
- **Top-2**: 94.92%
- **Top-3**: 96.40%
- **Top-4**: 97.88%
- **Top-5**: 98.31%

## ğŸ› ï¸ Technical Implementation

### Data Preprocessing
- **RandomResizedCrop** (224Ã—224) for spatial variability
- **RandomHorizontalFlip** for data augmentation
- **ImageNet normalization** for transfer learning compatibility

### Training Strategy
- **Transfer Learning** with pre-trained ImageNet weights
- **Adam optimizer** with learning rate scheduling
- **Cross-entropy loss** for multi-class classification
- **Early stopping** to prevent overfitting

## ğŸ“ Project Structure

```
neural_networks/
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ Tree_Classification_Report.md       # Detailed technical report
â”œâ”€â”€ results_summary.txt                 # Performance summary
â”œâ”€â”€ exercise_release.ipynb             # Main notebook
â”œâ”€â”€ exercise_release â€“ kopio.ipynb     # Notebook copy
â”œâ”€â”€ tree_dataset/                      # Dataset directory
â”‚   â”œâ”€â”€ train/                         # Training images (23 classes)
â”‚   â”œâ”€â”€ val/                           # Validation images
â”‚   â””â”€â”€ test/                          # Test images
â””â”€â”€ *.pth                              # Trained model weights
    â”œâ”€â”€ resnet18_tree_classifier.pth
    â”œâ”€â”€ resnet50_tree_classifier.pth
    â”œâ”€â”€ resnet18_feature_extract_tree_classifier.pth
    â”œâ”€â”€ resnet50_feature_extract_tree_classifier.pth
    â”œâ”€â”€ resnet18_high_lr_tree_classifier.pth
    â””â”€â”€ resnet50_feature_extract_long_tree_classifier.pth
```

## ğŸš€ Getting Started

### Prerequisites
```bash
torch>=1.9.0
torchvision>=0.10.0
numpy
matplotlib
PIL
sklearn
```

### Running the Project
1. Clone the repository
2. Ensure the `tree_dataset/` directory contains the properly structured data
3. Open `exercise_release.ipynb` in Jupyter Notebook
4. Run cells sequentially to train and evaluate models

### Model Loading
```python
import torch
model = torch.load('resnet50_tree_classifier.pth')
model.eval()
```

## ğŸ“‹ Results Summary

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|---------|----------|
| ResNet18 (Fine-tune) | 84.96% | 86.44% | 84.96% | 84.62% |
| **ResNet50 (Fine-tune)** | **89.62%** | **91.08%** | **89.62%** | **89.70%** |
| ResNet18 (Feature Extract) | 56.14% | 56.38% | 56.14% | 54.28% |
| ResNet50 (Feature Extract) | 54.45% | 56.49% | 54.45% | 53.05% |

## ğŸ” Key Findings

1. **Fine-tuning outperforms feature extraction** significantly
2. **ResNet50 superior to ResNet18** for this dataset
3. **Data augmentation crucial** for generalization
4. **Transfer learning highly effective** for limited dataset sizes
5. **N-best classification** shows excellent top-5 performance (98.31%)

## ğŸ“– Documentation

For detailed methodology, experimental setup, and comprehensive analysis, see:
- `Tree_Classification_Report.md` - Complete technical report
- `results_summary.txt` - Raw performance metrics
- `exercise_release.ipynb` - Implementation notebook

## ğŸ‘¨â€ğŸ’» Author

**Jani Timmerheid**  
Neural Networks Course Project  
November 2025

## ğŸ“„ License

This project is for educational purposes as part of a Neural Networks course.

---

*This project demonstrates practical application of deep learning techniques for real-world image classification challenges, showcasing the effectiveness of transfer learning in computer vision tasks.*" 
